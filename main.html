<!DOCTYPE html>
<html lang="ja">

<head>
    <title>arTryOnNail</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
</head>

<body>
    <div><img src="test.png" style="display: none;" id="input_image"></div>
    <!--div><img src="./archive/images/d60a5f06-db67-11e8-9658-0242ac1c0002.jpg" style="display: none;" id="input_image"></div-->
    <div></div><video id="video"></video></div>
    <span id="result" style="font-size: 48pt;"></span>
    <div><canvas id="result1"></canvas></div>
    <div><canvas id="input_img" style="display: none;"></canvas></div>
    <div><canvas id="output_img"></canvas></div>
    <p id="time"></p>

    <script src="https://unpkg.com/three@0.140.0/examples/js/libs/stats.min.js" crossorigin="anonymous"></script>
    <script async src="./opencv.js" type="text/javascript"></script>


    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>

    <!-- Import @tensorflow/tfjs-tflite -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/tf-tflite.min.js"></script>

    <!-- Place your code in the script tag below. You can also use an external .js file -->
    <script>
        // Notice there is no 'import' statement. 'tf' is available on the index-page
        // because of the script tag above.

        // Stats
        const stats = new Stats();
        stats.setMode(0);
        stats.domElement.style.position = "absolute";
        stats.domElement.style.left = "0px";
        stats.domElement.style.top = "0px";
        document.body.appendChild(stats.dom);

        // Parameters
        const CANVAS_SIZE = [224, 224];
        const TARGET_AREA = [0.25, 0.25, 0.75, 0.75]; // y1, x1, y2, x2
        const WEBCAM_CONFIG = { facingMode: "environment" };
        let MODEL_SIZE = [-1, -1, -1, -1]; // NHWC. get from model

        async function initCam() {
            // const videoElement = document.createElement("video");
            try {
                const videoElement = document.getElementById("video")
                videoElement.width = CANVAS_SIZE[0];
                videoElement.height = CANVAS_SIZE[1];
                const cam = await tf.data.webcam(videoElement, WEBCAM_CONFIG);
                return cam;
            } catch (e) {
                alert("[initCam] failed");
                alert(e.message);
                return null;
            }
        }

        async function initModel() {
            try {
                //let model = await tflite.loadTFLiteModel("./nails1105.tflite");
                const path = "./model_nails1105_lite/model.json";
                let model = await tf.loadGraphModel(path); // TensorFlow SavedModelまたはTensorFlow HubモジュールのAPI 
                MODEL_SIZE = model.input.shape;
                return model;
            } catch (e) {
                alert("[initModel] failed");
                alert(e.message);
                return null;
            }
        }

        async function getImage(cam) {
            const imgCam = await cam.capture(); /* [300x300x3] tensor */

            console.log(imgCam.shape);

            const processedImg = tf.tidy(() => {
                /* Crop center and Resize to model input size (28x28) */
                /* need expandDims and squeeze to cropAndResize */
                let img = tf.image.cropAndResize(imgCam.expandDims(), [TARGET_AREA], [0], [MODEL_SIZE[2], MODEL_SIZE[3]]).squeeze()

                // /* 0.0 - 1.0 */
                // img = img.cast("float32").div(tf.scalar(255));
                /* Normalize */
                img = img.cast("float32").div(127.5).sub(1);

                img = imgCam
                    .toFloat()
                    .resizeNearestNeighbor([224, 224])
                    // Normalize.
                    .expandDims()
                    .div(127.5)
                    .sub(1);

                console.log(img.shape);

                img = tf.transpose(img, perm = [0, 3, 1, 2]);
                console.log(img.shape);

                return img;
            });
            imgCam.dispose();

            /* expand dimension (HWC ->  NHWC) */
            //return processedImg.expandDims();
            return processedImg;
        }

        async function run() {
            //const model = await tflite.loadTFLiteModel("https://storage.googleapis.com/tfweb/models/cartoongan_fp16.tflite");
            //const model = await tflite.loadTFLiteModel("./nails1105.tflite");
            //const model = await tflite.loadTFLiteModel("./nails_segmentation.tflite");

            // load model
            const path = "./model_nails1105_lite/model.json";
            const model = await tf.loadGraphModel(path); // TensorFlow SavedModelまたはTensorFlow HubモジュールのAPI 
            //const model = await tf.loadLayersModel(path);// Kerasモデル

            const input = tf.browser
                .fromPixels(document.getElementById('input_image'), 3)
                //.fromPixels(document.getElementById('input_image'), 1)
                .toFloat()
                .resizeNearestNeighbor([224, 224])
                // Normalize.
                .expandDims()
                .div(127.5)
                .sub(1);
            //.div(tf.scalar(255))
            //.expandDims();

            console.log(input.shape);
            input.print();
            let input_reshape = tf.transpose(input, perm = [0, 3, 1, 2]);
            console.log(input_reshape.shape);
            input_reshape.print();


            MODEL_SIZE = model.inputs[0].shape;
            const cam = await initCam();

            //await process(model, cam);
            setInterval(() => {
                process(model, cam); //three jsの処理を少しずらさないとios safariでtexture.needsUpdateが反映されない
            //}, 2000);
            }, 1);

        }
        run();

        async function process(model, cam) {
            stats.update(); // 毎フレームごとにstats.update()を呼ぶ必要がある。

            // Get image and pre process
            const t0 = performance.now();
            const inputTensor = await getImage(cam);

            console.log(inputTensor);

            // Inference
            const t1 = performance.now();
            //let input_reshape = tf.transpose(inputTensor, perm = [0, 3, 1, 2]);
            const outputTensor = await model.predict([inputTensor]);
            //console.log(outputTensor.shape);
            //input_reshape.dispose();
            let tmp_canvas = document.getElementById("input_img");
            tmp_canvas.width = inputTensor.shape[3];
            tmp_canvas.height = inputTensor.shape[2];
            console.log(inputTensor.shape);
            inputTensor.print();
            let input_reshape = inputTensor.squeeze();
            console.log(input_reshape.shape);
            input_reshape.print();
            let tmp_inputImg = tf.transpose(input_reshape, perm = [1, 2, 0]);
            // De-normalize.
            let threshold_tensor = tmp_inputImg.add(1).mul(127.5).div(tf.scalar(255));
            console.log(tmp_inputImg.shape);
            await tf.browser.toPixels(threshold_tensor, tmp_canvas);
            threshold_tensor.dispose();
            tmp_inputImg.dispose();
            input_reshape.dispose();

            inputTensor.dispose();

            // Display result
            const t2 = performance.now();
            // Draw on canvas.
            let canvas = document.getElementById("result1");
            canvas.width = outputTensor.shape[3];
            canvas.height = outputTensor.shape[2];
            console.log(outputTensor.shape);
            outputTensor.print();
            let tmp = outputTensor.squeeze();
            console.log(tmp.shape);
            tmp.print();
            await tf.browser.toPixels(tmp, canvas);
            outputTensor.dispose();
            tmp.dispose();

            // opencvで画像合成：爪塗りつぶし
            //videoソース読み込み
            let src = cv.imread('input_img');
            let mask = cv.imread('result1');
            let dst = new cv.Mat(src.cols, src.rows, cv.CV_8UC3);

            for (var i = 0; i < src.rows; i++) {
                for (var j = 0; j < src.cols; j++) {
                    //完全な二値化はしていないので、黒部分でも2,5など必ずしも0ではないので、閾値で場合分け
                    if (mask.ucharPtr(i, j)[0] < 50) {
                        dst.ucharPtr(i, j)[0] = src.ucharPtr(i, j)[0];
                        dst.ucharPtr(i, j)[1] = src.ucharPtr(i, j)[1];
                        dst.ucharPtr(i, j)[2] = src.ucharPtr(i, j)[2];
                    }
                    else {
                        // ToDo:塗り潰したい色情報をネイル画像から抽出して合成
                        // 現状はひとまず赤色で塗り潰し
                        dst.ucharPtr(i, j)[0] = 255;
                        dst.ucharPtr(i, j)[1] = 0;
                        dst.ucharPtr(i, j)[2] = 0;
                    }
                }
            }
            cv.imshow('output_img', dst);
            src.delete();
            mask.delete();
            dst.delete();

            const t3 = performance.now();
            document.getElementById("time").innerHTML = `Time[ms]: Total = ${(t3 - t0).toFixed(3)},
            PreProcess = ${(t1 - t0).toFixed(3)},
            Inference = ${(t2 - t1).toFixed(3)}`;
            return null;
        }

        // 大津の2値化
        class ImageProc {
            /**
             * メイン
             * @param {Object} canvas 
             * @param {Object} image 
             */
            main(canvas, image) {
                const grayscale = (r, g, b) => 0.2126 * r + 0.7152 * g + 0.0722 * b
                let ctx = canvas.getContext("2d");
                ctx.drawImage(image, 0, 0, image.width, image.height)
                let src = ctx.getImageData(0, 0, image.width, image.height)
                let dst = ctx.createImageData(image.width, image.height)

                let t = this.threshold(src)

                for (let i = 0; i < dst.data.length; i += 4) {
                    let v = grayscale(src.data[i], src.data[i + 1], src.data[i + 2])
                    if (v < t) {
                        dst.data[i] = dst.data[i + 1] = dst.data[i + 2] = 0
                    } else {
                        dst.data[i] = dst.data[i + 1] = dst.data[i + 2] = 255
                    }
                    dst.data[i + 3] = 255
                }
                ctx.putImageData(dst, 0, 0)
            }
            /**
             * 大津の2値化
             * @param {ImageData} src
             */
            threshold(src) {
                const grayscale = (r, g, b) => 0.2126 * r + 0.7152 * g + 0.0722 * b
                let histgram = Array(256).fill(0)
                let t = 0
                let max = 0

                for (let i = 0; i < src.data.length; i += 4) {
                    let g = ~~grayscale(src.data[i], src.data[i + 1], src.data[i + 2])
                    histgram[g]++
                }

                for (let i = 0; i < 256; i++) {
                    let w1 = 0
                    let w2 = 0
                    let sum1 = 0
                    let sum2 = 0
                    let m1 = 0
                    let m2 = 0
                    for (let j = 0; j <= i; ++j) {
                        w1 += histgram[j]
                        sum1 += j * histgram[j]
                    }
                    for (let j = i + 1; j < 256; ++j) {
                        w2 += histgram[j]
                        sum2 += j * histgram[j]
                    }
                    if (w1) {
                        m1 = sum1 / w1
                    }
                    if (w2) {
                        m2 = sum2 / w2
                    }
                    let tmp = (w1 * w2 * (m1 - m2) * (m1 - m2))
                    if (tmp > max) {
                        max = tmp
                        t = i
                    }
                }
                return t
            }
        }

    </script>
</body>

</html>